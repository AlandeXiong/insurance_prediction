# Configuration file for Insurance Renewal Prediction

data:
  # Data split strategy (ONLY 3 supported):
  # - pre_split: use already-split train/test files on disk
  # - timecut: split the original source file by a date cutoff (time-based holdout)
  # - ratio: random split the original source file by test_size (optionally stratified)
  strategy: "pre_split"  # "pre_split" | "timecut" | "ratio"

  # Common settings
  target_column: "Response"
  random_state: 42
  source_path: "dataset/WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv"

  # Strategy 1) pre_split: use pre-generated train/test files
  pre_split:
    train_path: "dataset/train.csv"
    test_path: "dataset/test.csv"

  # Strategy 2) timecut: time-based split from the original file (no need to pre-generate CSVs)
  timecut:
    date_col: "Effective To Date"
    cutoff: "2011-02-20"  # dates <= cutoff go to train

  # Strategy 3) ratio: random split from the original file
  ratio:
    test_size: 0.2
    stratify: true

features:
  # Set to true to auto-discover features from data
  use_auto_discovery: false

  categorical_features:
    - "State"
    - "Coverage"
    - "Education"
    - "EmploymentStatus"
    - "Gender"
    - "Location Code"
    - "Marital Status"
    - "Policy Type"
    - "Policy"
    - "Renew Offer Type"
    - "Sales Channel"
    - "Vehicle Class"
    - "Vehicle Size"
  
  numerical_features:
    - "Customer Lifetime Value"
    - "Income"
    - "Monthly Premium Auto"
    - "Months Since Last Claim"
    - "Months Since Policy Inception"
    - "Number of Open Complaints"
    - "Number of Policies"
    - "Total Claim Amount"
  
  drop_features:
    - "Customer"
    - "Effective To Date"

  # Date-derived features (recommended for time-based evaluation/generalization)
  # When enabled, we keep 'Effective To Date' long enough to derive:
  # - Effective_To_Date_Month / Day / Weekday / Quarter
  # Then we drop the raw 'Effective To Date' column from the final model matrix.
  date_features:
    effective_to_date:
      enabled: true
      drop_original: true

model:
  models:
    - "lightgbm"
    - "xgboost"
    - "catboost"
    - "ensemble"
  
  cv_folds: 5
  # CV scoring metric used during Optuna tuning and optional CV reporting.
  # For imbalanced data, prefer "average_precision" or "roc_auc".
  scoring: "roc_auc"
  # BEST MODEL selection:
  # - selection_dataset: choose best model on "validation" (recommended) to avoid test-set selection bias.
  # - metric: which metric to use for selection.
  # - fallback_metric: used when the primary metric is not actionable (e.g., business_score all zeros).
  best_model_selection_dataset: "validation"  # "validation" | "test"
  best_model_metric: "business_score"         # "business_score" | "pr_auc" | "roc_auc" | ...
  best_model_fallback_metric: "pr_auc"
  n_trials: 100
  
  # Business constraints for imbalanced classification (threshold moving)
  # Goal: ensure Recall >= min_recall AND Precision >= min_precision
  # Business target: keep recall high (dataset positive ratio ~0.15),
  # then maximize precision under that recall constraint.
  min_recall: 0.5
  # min_precision: 0.25
  # Threshold strategy:
  # - fixed: use config.yaml thresholds below
  # - validation: pick threshold on a validation set to satisfy min_recall and maximize precision
  threshold_strategy: "validation"  # "fixed" or "validation"
  optimize_threshold: false  # kept for backward compatibility; ignored when threshold_strategy="validation"
  thresholds:
    default: 0.5
    lightgbm: 0.30
    xgboost: 0.34
    catboost: 0.38
    ensemble: 0.35
  
  ensemble:
    method: "voting"  # voting or stacking
    weights: null  # null for auto, or list of weights

training:
  # Training mode: "fast" for quick testing, "full" for production
  # Fast mode: fewer optimization trials, faster training
  # Full mode: more optimization trials, better performance
  mode: "fast"  # "fast" or "full"
  
  # Fast mode settings (used when mode="fast")
  fast:
    n_trials: 15  # Reduced optimization trials
    cv_folds: 3  # Fewer CV folds
    models: ["lightgbm", "xgboost", "catboost", "ensemble"]  # Fewer models to train
    # FAST tuning settings (speed-first)
    # - strategy: "holdout" runs ONE stratified split per Optuna trial (much faster than KFold)
    # - budgets: cap estimators/iterations during tuning only
    tuning:
      strategy: "holdout"
      holdout_size: 0.2
      early_stopping_rounds: 30
      lightgbm_n_estimators: 800
      xgboost_n_estimators: 600
      catboost_iterations: 600
      catboost_od_wait: 30

  # Validation split used for threshold selection when model.threshold_strategy="validation"
  validation:
    strategy: "auto"          # "auto" | "time_holdout" | "holdout"
    holdout_size: 0.2
    date_col: "Effective To Date"
  
  # Full mode settings (used when mode="full")
  full:
    n_trials: 100  # Full optimization trials
    cv_folds: 5  # Standard CV folds
    models: ["lightgbm", "xgboost", "catboost", "ensemble"]  # All models
  
  early_stopping_rounds: 50
  verbose: true
  use_gpu: false

api:
  host: "0.0.0.0"
  port: 8000
  reload: false

paths:
  models_dir: "models"
  outputs_dir: "outputs"
  logs_dir: "logs"

# Post-training analysis
analysis:
  shap:
    enabled: true
    # Which model to explain: "best" or a specific name ("lightgbm" | "xgboost" | "catboost" | "ensemble")
    model: "best"
    # Which dataset to explain: "train" | "validation" | "test"
    dataset: "train"
    sample_size: 1000
    background_size: 200
    max_display: 20
