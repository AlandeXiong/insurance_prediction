# Configuration file for Insurance Renewal Prediction

data:
  # Paths for separate train and test files
  train_path: "dataset/WA_Fn-UseC_-Marketing-Customer-Value-Analysis—train.csv"
  test_path: "dataset/WA_Fn-UseC_-Marketing-Customer-Value-Analysis—test.csv"
  
  # If train_path and test_path are provided, they will be used
  # Otherwise, single file will be split using test_size
  use_separate_files: true  # Set to true to use separate train/test files
  
  target_column: "Response"
  test_size: 0.2  # Only used if use_separate_files is false
  random_state: 42
  stratify: true  # Only used if use_separate_files is false

features:
  # Set to true to auto-discover features from data
  use_auto_discovery: false

  categorical_features:
    - "State"
    - "Coverage"
    - "Education"
    - "EmploymentStatus"
    - "Gender"
    - "Location Code"
    - "Marital Status"
    - "Policy Type"
    - "Policy"
    - "Renew Offer Type"
    - "Sales Channel"
    - "Vehicle Class"
    - "Vehicle Size"
  
  numerical_features:
    - "Customer Lifetime Value"
    - "Income"
    - "Monthly Premium Auto"
    - "Months Since Last Claim"
    - "Months Since Policy Inception"
    - "Number of Open Complaints"
    - "Number of Policies"
    - "Total Claim Amount"
  
  drop_features:
    - "Customer"
    - "Effective To Date"

model:
  models:
    - "lightgbm"
    - "xgboost"
    - "catboost"
    - "ensemble"
  
  cv_folds: 5
  scoring: "precision_at_min_recall"  # Primary goal: maximize precision with recall >= min_recall
  n_trials: 100
  
  # Business constraints for imbalanced classification (threshold moving)
  # Goal: ensure Recall >= min_recall AND Precision >= min_precision
  # Business target: keep recall high (dataset positive ratio ~0.15),
  # then maximize precision under that recall constraint.
  min_recall: 0.6
  min_precision: 0.25
  optimize_threshold: true  # Optimize threshold to meet recall requirement
  # Threshold selection policy under constraints:
  # - max_precision: maximize precision (can yield very high thresholds and unstable recall on test)
  # - max_recall: maximize recall under precision constraint (recommended when recall is critical)
  # If your test recall is still too low (common when test probabilities are less calibrated/lower),
  # use the more aggressive recall-first strategy below.
  # For "maximize precision under recall>=min_recall", use:
  threshold_selection: "max_f1"
  
  ensemble:
    method: "voting"  # voting or stacking
    weights: null  # null for auto, or list of weights

training:
  # Training mode: "fast" for quick testing, "full" for production
  # Fast mode: fewer optimization trials, faster training
  # Full mode: more optimization trials, better performance
  mode: "fast"  # "fast" or "full"
  
  # Fast mode settings (used when mode="fast")
  fast:
    n_trials: 20  # Reduced optimization trials
    cv_folds: 3  # Fewer CV folds
    models: ["lightgbm", "xgboost", "catboost", "ensemble"]  # Fewer models to train
  
  # Full mode settings (used when mode="full")
  full:
    n_trials: 100  # Full optimization trials
    cv_folds: 5  # Standard CV folds
    models: ["lightgbm", "xgboost", "catboost", "ensemble"]  # All models
  
  early_stopping_rounds: 100
  verbose: true
  use_gpu: false

api:
  host: "0.0.0.0"
  port: 8000
  reload: false

paths:
  models_dir: "models"
  outputs_dir: "outputs"
  logs_dir: "logs"
